uvloop is not installed. Falling back to the default asyncio event loop. Please install uvloop for better performance using `pip install uvloop`.
uvloop is not installed. Falling back to the default asyncio event loop.
{'access_token': None,
 'checkpoint_dir': WindowsPath('checkpoints/TinyLlama/TinyLlama-1.1B-Chat-v1.0'),
 'data': JSON(json_path=WindowsPath('train.json'),
              mask_prompt=False,
              val_split_fraction=0.05,
              prompt_style=<litgpt.prompts.Alpaca object at 0x0000027815BE4B90>,
              ignore_index=-100,
              seed=42,
              num_workers=4),
 'devices': 1,
 'eval': EvalArgs(interval=1000,
                  max_new_tokens=100,
                  max_iters=100,
                  initial_validation=False,
                  final_validation=True,
                  evaluate_example='first'),
 'logger_name': 'csv',
 'num_nodes': 1,
 'optimizer': 'AdamW',
 'out_dir': WindowsPath('tiny_llama_adapter_fintune_on_squad_v1'),
 'precision': 'bf16-true',
 'quantize': None,
 'seed': 1337,
 'train': TrainArgs(save_interval=1000,
                    log_interval=50,
                    global_batch_size=16,
                    micro_batch_size=2,
                    lr_warmup_steps=100,
                    lr_warmup_fraction=None,
                    epochs=5,
                    max_tokens=None,
                    max_steps=None,
                    max_seq_length=None,
                    tie_embeddings=None,
                    max_norm=None,
                    min_lr=6e-05)}
Seed set to 1337
Number of trainable parameters: 410,240
Number of non-trainable parameters: 1,100,048,384
The longest sequence length in the train data is 1156, the model's maximum sequence length is 1156 and context length is 2048
Verifying settings ...
