{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3639a352-86bf-4a41-9b4a-1d88304c4c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "\n",
    "import json\n",
    "\n",
    "with open(\"test.json\", \"r\") as json_file:\n",
    "    test_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52da817-8d44-4fba-97bc-74dbc1a24360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction_text = (\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "\n",
    "    return instruction_text + input_text\n",
    "\n",
    "print(format_input(test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79331be-add6-44e5-8708-9ee40f2ff827",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_chaithra= {\n",
    "\"instruction\": \"Name: Chaithra M,  Date of birth: 29/06/1996 Nationality: Indian Gender: Female  Phone number:  (+49) 15560015477 (Mobile)  Email address: chaithramgowda29@gmail.com   Address: Schweriner Straße 25, 01097, Dresden, Germany (Home)   As a Cost Management Accountant in India, I have earned certifications in Workday Procure to Pay and Adaptive Advance Level. Currently, I am utilizing my expertise as a Workday Finance Consultant at Price Water Coopers Pvt Ltd, where I have accumulated two years of experience in this domain. Prior to this role, I served as a Senior Finance Executive proficient in ERP Oracle, overseeing Accounts Receivable and reporting functions. Starting in 2024, I am planning to relocate to Germany and actively seeking job opportunities in the same domain in Germany. 01/07/2024 – CURRENT Berlin, Germany WORKDAY FINANCIAL LEAD N26 PRODUCT AND TECH GMBH •Configured and maintained Workday Financials, testing and documenting system improvements and bug fixes. •Collaborated with Finance, Sourcing, and TechOps to enhance our technology landscape and integrations. •Partnered with stakeholders to identify needs and improve employee experiences through workday software. •Led decisions on business processes, design, and architecture, using business process mapping. •Managed release cycles for new functionalities to align with business needs. •Supported users and resolved issues using Jira, collaborating with vendors when necessary. •Led projects to implement new solutions and enhance business capabilities. •Analyzed technology metrics to support strategic decisions and continuous improvement. •Ensured data integrity through data management and architecture support. •Provided stakeholders with Workday reports to enable data-driven decisions. •Worked with composite reports and dashboards to meet the workday finance stake holders requirements\"\n",
    " ,\"input\" : \"who is Chaithra?\"   \n",
    "}\n",
    "input_thesis = {\n",
    "    \"instruction\" : \"\"\"A Multi-Task Neural Network (MTNN) is a type of network in the field of machine learning\n",
    " where a single large neural network learns to solve multiple tasks simultaneously. In this paper,\n",
    " the performance of MTNNs is compared with that of corresponding Single-Task Neural Networks\n",
    " (STNN). The primary focus of this paper is on four autonomous driving perception tasks: semantic\n",
    " segmentation, lane marking, drivable area, and object detection. The Audi Autonomous Driving\n",
    " Dataset (A2D2) is used for the experiments. The dataset contains semantic segmentation labels\n",
    " for 57 classes (including labels for lane marking and drivable area) and 2D bounding boxes for\n",
    " 14 classes for 12,497 images. Here, we first implement and train STNNs, then MTNNs for all\n",
    " the combinations of our four primary tasks. The MTNN used here has a shared encoder and one\n",
    " decoder for each task. Introduced new loss weighing and training techniques for better optimization\n",
    " of MTNNs. Based on the experiment results, multi-task learning outperforms single-task learning\n",
    " both in speed and accuracy. MTNNs are up to 33% faster, with improvement in accuracy of\n",
    " semantic segmentation up to 1%, lane marking up to 2.5%, drivable area up to 1.5%, and object\n",
    " detection up to 12%. Further, transfer learning method is used to train STNNs with MTNN’s\n",
    " shared encoder weights. Results show improvement in STNNs accuracy up to 2%. Also, it shows\n",
    " that MTNN’s shared encoder has learned better generalized feature representations on the A2D2\n",
    " dataset. Finally, an MTNN with object detection as its primary task and semantic segmentation\n",
    " as an auxiliary task is trained on A2D2 dataset. The labels for auxiliary task were generated using\n",
    " DeepLabv3 architecture model pre-trained on CityScapes and BDD dataset. The results show that\n",
    " the object detection mAP score was improved by 6.94%.\"\"\",\n",
    "    \"input\" : \"What is MTNN?\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2370ba-e728-4ef7-9742-385fc985622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from litgpt import LLM\n",
    "\n",
    "llm = LLM.load(\"meta_llama_32_finetuned_on_sqaud/finetune/lora/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166591e5-27b8-49ec-bb19-df8b033be484",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm2 = LLM.load(\"tiny_llama_lora_fintune_on_squad_v1/final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96d36b6-6bee-45bf-917e-55bf88b0ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm3 = LLM.load(\"tiny_llama_lora_fintune_on_squad_v1-v2-fu rther2-lr6e1/final\")\n",
    "llm4 = LLM.load(\"tiny_llama_lora_fintune_on_squad_v1-v2-further-lr6e6/final\")\n",
    "llm5 = LLM.load(\"tiny_llama_lora_finetune_on_squad_v1-v2/final\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef173e2e-580c-4ac5-a9c2-b4318dde58a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the training data\n",
    "with open(\"qa_dataset/train_squad_v1_v2_hotpot.json\", \"r\") as json_file:\n",
    "    train_data = json.load(json_file)\n",
    "\n",
    "# Initialize the tokenizer (use a general tokenizer, like LLama or GPT-2)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")  # Replace with your model's tokenizer if different\n",
    "\n",
    "# Function to format input as in your provided code\n",
    "def format_input(entry):\n",
    "    instruction_text = f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text\n",
    "\n",
    "# Calculate the maximum token size\n",
    "max_token_count = 0\n",
    "max_entry = None  # To keep track of the longest entry\n",
    "tokens_morethan_2048 = 0\n",
    "\n",
    "examples_less_than_2048 = []\n",
    "for entry in tqdm(train_data):\n",
    "    formatted_text = format_input(entry)\n",
    "    tokenized = tokenizer(formatted_text, truncation=False, return_tensors=None)\n",
    "    token_count = len(tokenized[\"input_ids\"])\n",
    "    \n",
    "    if token_count > 1800:\n",
    "        tokens_morethan_2048 += 1\n",
    "        continue\n",
    "    examples_less_than_2048.append(entry)\n",
    "        #max_entry = entry\n",
    "print(f\"Examples more than 2048 tokens : {tokens_morethan_2048}\")\n",
    "#print(f\"Maximum token size: {max_token_count}\")\n",
    "#print(\"Longest entry:\")\n",
    "#print(format_input(max_entry))\n",
    "\n",
    "with open(\"train_v1_v2_hotpot_max_1800.json\", \"w\") as file2:\n",
    "    json.dump(examples_less_than_2048, file2, indent=4)\n",
    "\n",
    "\"\"\"\n",
    "for test_squad_v1_v2_hotpot.json\n",
    "Examples more than 2048 tokens : 112\n",
    "Maximum token size: 0\n",
    "Longest entry:\n",
    "\n",
    "for train_squad_v1_v2_hotpot.json\n",
    "Examples more than 2048 tokens : 2175\n",
    "Examples more than 2000 tokens : \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863ade4c-c003-4ce3-a8f8-223a2ecd4d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = input_thesis\n",
    "test_sample[\"input\"] = \"How much MTNNs are better than STNNs in terms of inference speed?\"\n",
    "print(\"llm1\",llm.generate(format_input(test_sample), top_k=1))\n",
    "print(\"llm2\",llm2.generate(format_input(test_sample), top_k=1))\n",
    "print(\"llm3\", llm3.generate(format_input(test_sample), top_k=1))\n",
    "print(\"llm4\", llm3.generate(format_input(test_sample), top_k=1))\n",
    "print(\"llm5\", llm3.generate(format_input(test_sample), top_k=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d857547-d99b-422f-afd2-1401682c80f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the training data\n",
    "with open(\"qa_dataset/train_squad_v1_v2_hotpot.json\", \"r\") as json_file:\n",
    "    train_data = json.load(json_file)\n",
    "\n",
    "# Initialize the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")  # Replace with your model's tokenizer if different\n",
    "max_token_length = 1400  # Define max token limit\n",
    "\n",
    "# Function to format input\n",
    "def format_input(entry):\n",
    "    instruction_text = f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    input_text = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction_text + input_text\n",
    "\n",
    "# Filter entries\n",
    "examples_less_than_max_tokens = []\n",
    "tokens_more_than_limit = 0\n",
    "\n",
    "for idx, entry in enumerate(tqdm(train_data, desc=\"Processing entries\")):\n",
    "    try:\n",
    "        formatted_text = format_input(entry)\n",
    "        tokenized = tokenizer(formatted_text, truncation=False, return_tensors=None)\n",
    "        token_count = len(tokenized[\"input_ids\"])\n",
    "\n",
    "        # Debug print for token count\n",
    "        if idx < 5:  # Print for the first few entries only\n",
    "            print(f\"Entry {idx} token count: {token_count}\")\n",
    "            print(f\"Formatted text: {formatted_text[:100]}...\")  # Print a snippet of the text\n",
    "\n",
    "        if token_count > max_token_length:\n",
    "            tokens_more_than_limit += 1\n",
    "            continue\n",
    "\n",
    "        examples_less_than_max_tokens.append(entry)\n",
    "    except KeyError as e:\n",
    "        print(f\"Missing key in entry {idx}: {e}\")\n",
    "\n",
    "# Summary\n",
    "print(f\"Total examples: {len(train_data)}\")\n",
    "print(f\"Examples exceeding {max_token_length} tokens: {tokens_more_than_limit}\")\n",
    "print(f\"Examples within token limit: {len(examples_less_than_max_tokens)}\")\n",
    "\n",
    "# Save filtered data\n",
    "output_file = \"train_v1_v2_hotpot_1400.json\"\n",
    "with open(output_file, \"w\") as file:\n",
    "    json.dump(examples_less_than_max_tokens, file, indent=4)\n",
    "print(f\"Filtered data saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa39d785-5924-4ac3-9e8c-797c34858887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd1e4b-9b57-4594-9136-5fe85405c53d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
